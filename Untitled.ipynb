{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences: 5510\n",
      "Sequences in training set: 4408\n",
      "Sequences in test set: 1102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "__author__ = 'Alejandro Fontal'\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "seqdir = curr_dir + \"/seqs/\"\n",
    "seqfiles = os.listdir(seqdir)\n",
    "aa_string = \"ARNDCEQGHILKMFPSTWYVX\"  # 20 aa + X\n",
    "\n",
    "\n",
    "def get_1h_dict(aa_string):\n",
    "    \"\"\"\n",
    "    Given a string of unique characters, generates dictionary of 1-hot vectors\n",
    "    with characters as keys and vectors as values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    aa_dict = {}\n",
    "\n",
    "    for idx, aa in enumerate(aa_string):\n",
    "\n",
    "        if idx > 0:\n",
    "            aa_dict[aa] = np.zeros(idx-1).tolist() + [1] +\\\n",
    "                          np.zeros(len(aa_string)-idx).tolist()\n",
    "        else:\n",
    "            aa_dict[aa] = [1] + np.zeros(len(aa_string)-1).tolist()\n",
    "\n",
    "    return aa_dict\n",
    "\n",
    "def seq2onehot(seq, aa_dict):\n",
    "    \"\"\"\n",
    "    Takes a sequence(string) of length n and a dictionary with m keys and\n",
    "    converts it to a 2 dimensional vector of nxm.\n",
    "\n",
    "    \"\"\"\n",
    "    onehot = []\n",
    "\n",
    "    # Convert ambiguous amino acids into actual ones.\n",
    "    for aa in seq:\n",
    "\n",
    "        if aa == \"Z\":\n",
    "            aa = \"Q\"\n",
    "        elif aa == \"B\":\n",
    "            aa = \"R\"\n",
    "        elif aa == \"J\":\n",
    "            aa = \"L\"\n",
    "\n",
    "        onehot += [aa_dict[aa]]\n",
    "\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def fasta_process(fasta_fn):\n",
    "    \"\"\"\n",
    "    :param fasta_fn: Filename of the FASTA file to parse\n",
    "    :return: A list containing the sequences in the FASTA file.\n",
    "    \"\"\"\n",
    "    with open(fasta_fn) as fasta_file:\n",
    "        fasta_list = fasta_file.read().splitlines()\n",
    "\n",
    "        parsed_seqs = []\n",
    "        for line in fasta_list:\n",
    "            if line.startswith(\">\"):\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                l = len(line)\n",
    "                if l > 1000:\n",
    "                    parsed_seqs.append(line[0:500] + line[l-500:l])\n",
    "\n",
    "                else:\n",
    "                    parsed_seqs.append(line[0:l] + \"X\"*(1000-l))\n",
    "\n",
    "    return parsed_seqs\n",
    "\n",
    "\n",
    "all_seqs = []\n",
    "\n",
    "for file in seqfiles:\n",
    "    all_seqs.append(fasta_process(seqdir+file))\n",
    "\n",
    "\n",
    "total_tensor = []\n",
    "\n",
    "aa_dict = get_1h_dict(aa_string)\n",
    "\n",
    "for idx, sub_loc in enumerate(all_seqs):\n",
    "\n",
    "    sublabel = np.zeros(len(all_seqs))\n",
    "    sublabel[idx] = 1\n",
    "\n",
    "    for seq in sub_loc:\n",
    "        total_tensor.append((sum(seq2onehot(seq, aa_dict), []), sublabel))\n",
    "\n",
    "print \"Total number of sequences: {}\".format(len(total_tensor))\n",
    "\n",
    "train_n = int(round(0.8 * len(total_tensor), 0))\n",
    "\n",
    "train_idxs = np.random.choice(len(total_tensor), train_n, replace=False)\n",
    "test_idxs = list(set(range(len(total_tensor))) - set(train_idxs))\n",
    "\n",
    "train_tensor = [total_tensor[i] for i in train_idxs]\n",
    "test_tensor = [total_tensor[i] for i in test_idxs]\n",
    "\n",
    "print \"Sequences in training set: {}\".format(len(train_tensor))\n",
    "print \"Sequences in test set: {}\\n\".format(len(test_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1:\n",
      "\n",
      "Train accuracy: 26.293%\t Test Accuracy: 26.41%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-36e964adadc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alejandro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \"\"\"\n\u001b[0;32m-> 1550\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alejandro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3762\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3764\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alejandro/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alejandro/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    936\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alejandro/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_labels = 10\n",
    "aa_vec_len = 21\n",
    "seq_len = 1000\n",
    "n_iters = 2000\n",
    "minibatch_size = 500\n",
    "learn_step = 0.5\n",
    "\n",
    "\n",
    "def get_batch(tensor, n=100):\n",
    "    \"\"\"Gets a minibatch from a tensor\n",
    "\n",
    "    Takes a tensor of shape t = [[[seq_1][lab_1]], ..., [[seq_n][lab_n]]] and\n",
    "    randomly takes n samples, returning a tensor x = [[seq_1], ..., [seq_n]]\n",
    "    and a tensor y = [[lab_1], ..., [lab_n]].\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(tensor), n, replace=False)\n",
    "    x = [tensor[i][0] for i in idxs]\n",
    "    y = [tensor[i][1] for i in idxs]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def weight_variable(shape, name=\"W\"):\n",
    "    \"\"\"Generates weight variables\n",
    "\n",
    "    Provides a tensor of weight variables obtained from a truncated normal\n",
    "    distribution with mean=0 and std=0.1. All values in range [-0.1, 0.1]\n",
    "    \"\"\"\n",
    "\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name=\"B\"):\n",
    "    \"\"\"Provides a tensor of bias variables with value 0.1\"\"\"\n",
    "\n",
    "\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "input_tensor = train_tensor  # Import train set\n",
    "\n",
    "test_set = test_tensor\n",
    "\n",
    "x_test = [test_set[i][0] for i in range(len(test_set))]\n",
    "y_test = [test_set[i][1] for i in range(len(test_set))]\n",
    "\n",
    "sess = tf.InteractiveSession()  # Start tensorflow session\n",
    "\n",
    "\n",
    "def fc_layer(input_tensor, input_dim, output_dim, name=\"fc\", relu=True):\n",
    "    \"\"\"Generates a fully connected layer with biases and weights\n",
    "\n",
    "    Computes a fully connected layer when provided with an input tensor and\n",
    "    returns an output tensor. Input and output channels must be specified.\n",
    "    By default, the output uses a ReLu activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        w = weight_variable([input_dim, output_dim])\n",
    "        b = bias_variable([output_dim])\n",
    "        out = tf.matmul(input_tensor, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "\n",
    "        if relu:\n",
    "            return tf.nn.relu(out)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "# Define variables of the network:\n",
    "x = tf.placeholder(tf.float32, [None, seq_len * aa_vec_len], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, n_labels], name=\"labels\")\n",
    "\n",
    "y = fc_layer(x, seq_len * aa_vec_len, n_labels, relu=False, name=\"fc\")\n",
    "\n",
    "tf.global_variables_initializer().run()  # Initialize variables\n",
    "\n",
    "#  Define cost_function (cross entropy):\n",
    "with tf.name_scope(\"crossentropy\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    tf.summary.scalar(\"crossentropy\", cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_step).\\\n",
    "        minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"/home/alejandro/Documents/GitHub/Thesis/logs\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for i in range(n_iters):\n",
    "    i += 1\n",
    "    a, b = get_batch(input_tensor, n=minibatch_size)\n",
    "    train_step.run(feed_dict={x: a, y_: b})\n",
    "    tf.summary.scalar(\"crossentropy\", cross_entropy)\n",
    "    \n",
    "    \"\"\"\n",
    "    if i % 5 == 0:\n",
    "        a, b = get_batch(input_tensor, n=minibatch_size)\n",
    "        [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: a, y_: b})\n",
    "        writer.add_summary(s, i)\n",
    "   \"\"\"\n",
    "    if i % 100 == 0 or i == 1:  # Check only in iterations multiple of 100\n",
    "        a, b = get_batch(input_tensor, n=len(input_tensor))  # Check in full train set\n",
    "        train_acc = accuracy.eval(feed_dict={x: a, y_: b})\n",
    "        test_acc = accuracy.eval(feed_dict={x: x_test, y_: y_test})\n",
    "        print \"Iteration number \" + str(i) + \":\\n\"\n",
    "        print \"Train accuracy: {}%\\t Test Accuracy: {}%\\n\".format(\n",
    "            round(train_acc*100, 3), round(test_acc*100, 2))\n",
    "\n",
    "        if train_acc == 1:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
